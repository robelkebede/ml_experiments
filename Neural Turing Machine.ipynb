{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import json \n",
    "from configs.task_generator import CopyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================                                                                   \n",
    "# Original Source: https://github.com/vlgiitr/ntm-pytorch/tree/master/ntm/datasets        \n",
    "# =====================    \n",
    "\n",
    "task_params = json.load(open(\"configs/copy.json\"))                                        \n",
    "                                                                                          \n",
    "dataset = CopyDataset(task_params)                                                        \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10])\n",
      "torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(dataset))\n",
    "\n",
    "x_,y_ = data[\"input\"],data[\"target\"]\n",
    "\n",
    "print(x_.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NTM,self).__init__()\n",
    "        \n",
    "        D_in = 10\n",
    "        D_out = 40\n",
    "        \n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        dim = 10\n",
    "        \n",
    "        self.controller = torch.nn.LSTMCell(D_in,D_out)\n",
    "        self.control_linear = nn.Linear(40,100)\n",
    "        \n",
    "        self.soft = nn.Softmax(dim=0)\n",
    "        self.out_net = nn.Linear(140,8)\n",
    "        \n",
    "        # prev reads\n",
    "        \n",
    "        self.prev_reads = []\n",
    "        \n",
    "        \n",
    "        # create a memory \n",
    "        N = 100 # number of location \n",
    "        M = 100 # size of location \n",
    "        self.memory = Variable(torch.ones(N,M))\n",
    "        \n",
    "        # layers for the read and write heads\n",
    "        self.w = nn.Linear(40,100) # weight \n",
    "        self.e = nn.Linear(100,100) # erase\n",
    "        self.a = nn.Linear(100,100) # add\n",
    "        \n",
    "\n",
    "        self.c_state = torch.zeros([1,dim])\n",
    "        self.h_state = torch.zeros([1,dim])\n",
    "    \n",
    "    def addressing(self,output):\n",
    "        \n",
    "      \n",
    "        beta = 2\n",
    "        \n",
    "        similarity_scores = F.cosine_similarity(output.unsqueeze(1), self.memory, dim=1)\n",
    "        \n",
    "        content_weights = F.softmax(beta * similarity_scores, dim=1) \n",
    "        \n",
    "        \n",
    "        return content_weights\n",
    "    \n",
    "    def output(self,reads):\n",
    "        \n",
    "        state_output = torch.cat([self.h_state,reads],dim=1)\n",
    "        \n",
    "        output = torch.sigmoid(self.out_net(state_output))\n",
    "        \n",
    "        return output\n",
    "               \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        \n",
    "        self.h_state,self.c_state = self.controller(x)\n",
    "        \n",
    "        control_output = self.control_linear(self.c_state)\n",
    "                \n",
    "        # modify the weights th be able to use in addressing \n",
    "        w = self.addressing(control_output)\n",
    "                              \n",
    "        # single head\n",
    "        \n",
    "        # read\n",
    "        read = torch.matmul(w , self.memory)\n",
    "        \n",
    "        \n",
    "        # erase \n",
    "        e_t = self.e(control_output) # Linear\n",
    "        \n",
    "        er = (1 - (w *  e_t)).resize(100,1)\n",
    "        erase = self.memory * er\n",
    "        \n",
    "        \n",
    "        # write \n",
    "        a_t = self.a(control_output) # Linear\n",
    "                \n",
    "        weight = w.detach()\n",
    "        det_erase = erase.detach()\n",
    "        \n",
    "        self.memory = det_erase + weight.T * a_t\n",
    "        #self.memory = torch.matmul(w.T , a_t)\n",
    "\n",
    "                \n",
    "        output = self.output(read)\n",
    "        \n",
    "        # put read write head hear        \n",
    "                \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() \n",
    "optimizer = torch.optim.RMSprop(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to calculate the cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.287558555603027\n",
      "28.022823333740234\n",
      "44.14920425415039\n",
      "41.2113151550293\n",
      "22.725820541381836\n",
      "28.060293197631836\n",
      "41.10667419433594\n",
      "34.75285339355469\n",
      "40.89961624145508\n",
      "40.06613540649414\n",
      "16.86406135559082\n",
      "43.476287841796875\n",
      "44.49610137939453\n",
      "58.766082763671875\n",
      "49.03845977783203\n",
      "62.5\n",
      "53.90625\n",
      "54.605262756347656\n",
      "47.65625\n",
      "45.0\n",
      "54.6875\n",
      "43.05555725097656\n",
      "37.5\n",
      "58.33333206176758\n",
      "48.21428680419922\n",
      "68.75\n",
      "39.16666793823242\n",
      "51.97368240356445\n",
      "55.55555725097656\n",
      "31.25\n",
      "45.83333206176758\n",
      "75.0\n",
      "49.264705657958984\n",
      "58.33333206176758\n",
      "52.88461685180664\n",
      "50.657894134521484\n",
      "51.04166793823242\n",
      "52.88461685180664\n",
      "50.0\n",
      "62.5\n",
      "46.875\n",
      "39.70588302612305\n",
      "41.66666793823242\n",
      "52.5\n",
      "57.14285659790039\n",
      "33.33333206176758\n",
      "50.0\n",
      "43.75\n",
      "45.83333206176758\n",
      "62.5\n",
      "50.0\n",
      "45.83333206176758\n",
      "52.67856979370117\n",
      "47.91666793823242\n",
      "50.0\n",
      "47.5\n",
      "40.0\n",
      "50.0\n",
      "44.73684310913086\n",
      "50.0\n",
      "52.77777862548828\n",
      "58.92856979370117\n",
      "51.66666793823242\n",
      "48.02631759643555\n",
      "60.41666793823242\n",
      "50.69444274902344\n",
      "53.125\n",
      "55.35714340209961\n",
      "47.91666793823242\n",
      "47.91666793823242\n",
      "56.25\n",
      "48.4375\n",
      "62.5\n",
      "57.5\n",
      "53.57143020629883\n",
      "50.0\n",
      "49.10714340209961\n",
      "47.91666793823242\n",
      "51.38888931274414\n",
      "47.32143020629883\n",
      "51.38888931274414\n",
      "52.5\n",
      "47.5\n",
      "46.52777862548828\n",
      "38.88888931274414\n",
      "53.67647171020508\n",
      "51.5625\n",
      "51.31578826904297\n",
      "47.91666793823242\n",
      "49.264705657958984\n",
      "52.77777862548828\n",
      "66.66666412353516\n",
      "52.77777862548828\n",
      "50.0\n",
      "52.34375\n",
      "45.588233947753906\n",
      "33.33333206176758\n",
      "50.0\n",
      "53.125\n",
      "58.33333206176758\n",
      "50.0\n",
      "62.5\n",
      "46.42856979370117\n",
      "52.5\n",
      "46.05263137817383\n",
      "50.0\n",
      "50.0\n",
      "57.29166793823242\n",
      "47.11538314819336\n",
      "50.0\n",
      "54.16666793823242\n",
      "51.38888931274414\n",
      "29.16666603088379\n",
      "51.97368240356445\n",
      "53.90625\n",
      "45.45454406738281\n",
      "49.264705657958984\n",
      "54.16666793823242\n",
      "51.5625\n",
      "46.71052551269531\n",
      "50.0\n",
      "51.38888931274414\n",
      "62.5\n",
      "48.4375\n",
      "44.44444274902344\n",
      "53.28947448730469\n",
      "45.0\n",
      "53.90625\n",
      "51.78571319580078\n",
      "37.5\n",
      "58.33333206176758\n",
      "45.83333206176758\n",
      "48.21428680419922\n",
      "46.05263137817383\n",
      "50.0\n",
      "54.54545593261719\n",
      "51.78571319580078\n",
      "48.8636360168457\n",
      "50.0\n",
      "56.25\n",
      "42.5\n",
      "55.0\n",
      "54.16666793823242\n",
      "75.0\n",
      "48.33333206176758\n",
      "43.75\n",
      "45.83333206176758\n",
      "46.59090805053711\n",
      "50.0\n",
      "45.83333206176758\n",
      "55.14706039428711\n",
      "46.875\n",
      "50.0\n",
      "42.85714340209961\n",
      "50.735294342041016\n",
      "37.5\n",
      "44.44444274902344\n",
      "50.0\n",
      "55.35714340209961\n",
      "46.153846740722656\n",
      "50.0\n",
      "41.66666793823242\n",
      "47.91666793823242\n",
      "44.53125\n",
      "31.25\n",
      "48.75\n",
      "46.25\n",
      "37.5\n",
      "56.25\n",
      "62.5\n",
      "52.5\n",
      "42.85714340209961\n",
      "48.61111068725586\n",
      "47.727272033691406\n",
      "56.25\n",
      "63.88888931274414\n",
      "55.921051025390625\n",
      "53.57143020629883\n",
      "40.27777862548828\n",
      "47.05882263183594\n",
      "75.0\n",
      "49.03845977783203\n",
      "60.41666793823242\n",
      "52.6315803527832\n",
      "50.0\n",
      "70.83333587646484\n",
      "50.0\n",
      "53.125\n",
      "40.97222137451172\n",
      "47.22222137451172\n",
      "54.411766052246094\n",
      "52.272727966308594\n",
      "40.44117736816406\n",
      "50.0\n",
      "62.5\n",
      "50.0\n",
      "50.83333206176758\n",
      "43.75\n",
      "35.41666793823242\n",
      "57.14285659790039\n",
      "46.875\n",
      "51.66666793823242\n",
      "53.75\n",
      "52.5\n",
      "46.875\n",
      "39.28571319580078\n",
      "52.6315803527832\n",
      "50.0\n",
      "48.61111068725586\n",
      "42.70833206176758\n",
      "67.5\n",
      "51.04166793823242\n",
      "62.5\n",
      "43.75\n",
      "56.25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '<ipython-input-5-6d1143440d95>'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8f91d0183fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6d1143440d95>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# modify the weights th be able to use in addressing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddressing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# single head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6d1143440d95>\u001b[0m in \u001b[0;36maddressing\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0msimilarity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mcontent_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/traceback.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    360\u001b[0m                 filename, lineno, name, lookup_line=False, locals=f_locals))\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# First call the original checkcache as intended\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# to our compiled codes can be produced.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mcontinue\u001b[0m   \u001b[0;31m# no-op for files loaded via a __loader__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "losses = []\n",
    "\n",
    "for data in dataset:\n",
    "    \n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "\n",
    "        X,y = data[\"input\"],data[\"target\"]\n",
    "        out = torch.zeros(y.size()) \n",
    "\n",
    "        zero_inputs = torch.zeros(X.size()[1]).unsqueeze(0) # dummy\n",
    "\n",
    "\n",
    "        for i in range(X.size()[0]):\n",
    "            model(X[i].unsqueeze(0))\n",
    "\n",
    "        for i in range(y.size()[0]):                                                     \n",
    "            out[i] = model(zero_inputs) \n",
    "\n",
    "\n",
    "        loss = criterion(out, y) \n",
    "\n",
    "        print(loss.item())\n",
    "\n",
    "        losses.append(loss.item())                                                            \n",
    "        loss.backward(retain_graph=True) \n",
    "        #loss.backward(retain_graph=True)\n",
    "        optimizer.step()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
